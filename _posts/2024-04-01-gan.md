---
layout: post
title: Generative Adversarial Network
date: 2024-04-01 
description: implementation of basic gan
tags: 
categories: machine_learning
related_posts: true
---


<!-- <h1 align="left" style="color:purple;font-size: 2em;" >Overview</h1> -->


<h2 style="color:purple;font-size: 2em;">Overview</h2>


* [1. Introduction](#section1)
* [2. Neural Netowork](#section2)
* [3. Model Training](#section3)
* [4. Results](#section4)
* [5. Evaluation](#section5)

##### Links to run the code
- [Google colab](https://colab.research.google.com/github/19revey/PINN_granular_segregation/blob/main/notebook/solver_segregation.ipynb)
- [Github repo](https://github.com/19revey/PINN_granular_segregation)

##### Understand the granular segregation and the transport equation
  - [[1] General Model For Segregation Forces in Flowing Granular Mixtures](https://arxiv.org/pdf/2309.13273.pdf)
  - [[2] Diffusion, mixing, and segregation in confined granular flows](https://arxiv.org/pdf/1809.08089.pdf)
  - [[3] On Mixing and Segregation: From Fluids and Maps to Granular Solids and Advection–Diffusion Systems](https://pubs.acs.org/doi/10.1021/acs.iecr.5b01268)

##### PINN implementation
  - [https://github.com/nanditadoloi/PINN](https://github.com/nanditadoloi/PINN)
  - [https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks](https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks)
  - [https://github.com/maziarraissi/PINNs](https://github.com/maziarraissi/PINNs)





<a class="anchor" id="section1"></a>
<h2 style="color:purple;font-size: 2em;">1. Introduction</h2>



<a class="anchor" id="section5"></a>
<h2 style="color:purple;font-size: 2em;">5. Evaluation </h2>

#### Univariate Fréchet Distance
You can calculate the distance between two normal distributions $$X$$ and $$Y$$ with means $$\mu_X$$ and $$\mu_Y$$ and standard deviations $$\sigma_X$$ and $$\sigma_Y$$, as:

$$d(X,Y) = (\mu_X-\mu_Y)^2 + (\sigma_X-\sigma_Y)^2 $$

#### Multivariate Fréchet Distance
**Covariance**

To find the Fréchet distance between two multivariate normal distributions, you first need to find the covariance instead of the standard deviation. The covariance, which is the multivariate version of variance (the square of standard deviation), is represented using a square matrix where the side length is equal to the number of dimensions. Since the feature vectors you will be using have 2048 values/weights, the covariance matrix will be 2048 x 2048. But for the sake of an example, this is a covariance matrix in a two-dimensional space:

$$\Sigma = \left(\begin{array}{cc} 
1 & 0\\ 
0 & 1
\end{array}\right)
$$

The value at location $(i, j)$ corresponds to the covariance of vector $i$ with vector $j$. Since the covariance of $i$ with $j$ and $j$ with $i$ are equivalent, the matrix will always be symmetric with respect to the diagonal. The diagonal is the covariance of that element with itself. In this example, there are zeros everywhere except the diagonal. That means that the two dimensions are independent of one another, they are completely unrelated.



* Feature extraction and Frechet Inception Distance (FID)
* KL Divergence $$D_{KL}= p(y\|x) log(\frac{p(y\|x)}{p(y)})$$
* Inception Score IS

- Comparison:
    - FID and IS both use the inception-V3 netowrk and look at samples, not the network parameters
    - FID compares reals and fakes, while IS only looks at fakes
    - FID uses imtermediate features from the inception-v3 network, while IS uses the classsifications directly